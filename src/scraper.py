"""
TKGM WFS Veri TarayÄ±cÄ±sÄ± - Ana Uygulama
TÃ¼rkiye Tapu ve Kadastro Genel MÃ¼dÃ¼rlÃ¼ÄŸÃ¼ parsel verilerini otomatik olarak toplar
"""

import os
import sys
import signal
from typing import Optional
from datetime import datetime, timedelta
from loguru import logger

# ModÃ¼lleri import et
from src.database import DatabaseManager
from src.telegram import TelegramNotifier
from src.client import TKGMClient
from .database import DatabaseManager
from .database.repositories import SettingsRepository
from .geometry import WFSGeometryProcessor
from src.config import settings


class TKGMScraper:
    """TKGM veri tarayÄ±cÄ±sÄ± ana sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        # Loglama ayarlarÄ±
        self._setup_logging()
        
        # Ã‡alÄ±ÅŸma durumu kontrolÃ¼ iÃ§in flag
        self.running = True
        
        # BileÅŸenleri baÅŸlat
        self._initialize_components()
        
        # Telegram bildirim modÃ¼lÃ¼
        self.notifier = TelegramNotifier()
        
        # Sinyal yakalayÄ±cÄ±larÄ± ayarla
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        logger.info("TKGM Veri TarayÄ±cÄ±sÄ± baÅŸlatÄ±ldÄ±")
    

    def _setup_logging(self):
        """Loglama sistemini ayarla"""
        log_level = settings.LOG_LEVEL
        log_file = settings.LOG_FILE
        
        # Log dizinini oluÅŸtur
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        # --- Self-Cleanup (FIFO) ---
        try:
            if os.path.exists(log_file):
                file_size = os.path.getsize(log_file)
                max_size = 100 * 1024 * 1024  # 100 MB
                keep_size = 50 * 1024 * 1024  # 50 MB
                
                if file_size > max_size:
                    print(f"Log dosyasÄ± boyutu sÄ±nÄ±rÄ± aÅŸtÄ± ({file_size/1024/1024:.2f} MB). Temizleniyor...")
                    
                    # Son keep_size kadar veriyi oku
                    with open(log_file, 'rb') as f:
                        f.seek(-keep_size, 2)  # Sondan geriye git
                        data = f.read()
                    
                    # DosyayÄ± yeniden yaz
                    with open(log_file, 'wb') as f:
                        f.write(data)
                        f.write(f"\n[CLEANUP] Log file truncated. Kept last {keep_size/1024/1024:.2f} MB.\n".encode('utf-8'))
                    
                    print("Log dosyasÄ± temizlendi.")
        except Exception as e:
            print(f"Log temizleme hatasÄ±: {e}")
        # ---------------------------
        
        # Mevcut loglarÄ± temizle
        logger.remove()
        
        # Konsol loglama
        logger.add(
            sys.stdout,
            level=log_level,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
        )
        
        # Dosya loglama
        logger.add(
            log_file,
            level=log_level,
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
        )
        
        logger.info(f"Loglama sistemi ayarlandÄ±: {log_level} seviyesi, dosya: {log_file}")


    def _initialize_components(self):
        """Sistem bileÅŸenlerini baÅŸlat"""
        try:
            # VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸtur
            self.db = DatabaseManager()

            # VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± test et
            if not self.db.test_connection():
                raise Exception("VeritabanÄ± baÄŸlantÄ±sÄ± kurulamadÄ±")
            
            # PostGIS uzantÄ±sÄ±nÄ± kontrol et
            if not self.db.check_postgis_extension():
                logger.warning("PostGIS uzantÄ±sÄ± bulunamadÄ±, geometri iÅŸlemleri Ã§alÄ±ÅŸmayabilir")
            
            # TablolarÄ± oluÅŸtur
            self.db.create_tables()
            
            # TKGM istemcisini baÅŸlat (DatabaseManager referansÄ± ile)
            self.client = TKGMClient(db_manager=self.db)
            # Test connection is skipped during initialization to avoid consuming daily limit
            # Use client.test_connection() manually when needed
            # if not self.client.test_connection():
            #     raise Exception("TKGM servis baÄŸlantÄ±sÄ± kurulamadÄ±")
            
            logger.info("TÃ¼m bileÅŸenler baÅŸarÄ±yla baÅŸlatÄ±ldÄ±")
            
        except Exception as e:
            logger.error(f"BileÅŸen baÅŸlatma hatasÄ±: {e}")
            sys.exit(1)
    

    def _signal_handler(self, signum, frame):
        """Sinyal yakalayÄ±cÄ±sÄ± (Ctrl+C, SIGTERM)"""
        # Birden fazla sinyalde tekrarlÄ± loglarÄ± Ã¶nle
        if not getattr(self, 'running', True):
            return
        logger.info(f"Sinyal alÄ±ndÄ±: {signum}, uygulama kapatÄ±lÄ±yor...")
        self.running = False
        # Ä°stemciyi mÃ¼mkÃ¼nse durdur ve oturumu kapat
        try:
            if hasattr(self, 'client') and self.client:
                self.client.running = False
                try:
                    self.client.timeout = 1  # sonraki denemelerde hÄ±zlÄ± zaman aÅŸÄ±mÄ±
                    self.client.session.close()
                except Exception:
                    pass
        except Exception:
            pass
        # Ana akÄ±ÅŸÄ± derhal sonlandÄ±r
        raise KeyboardInterrupt


    def sync_districts(self):
        """Ä°lÃ§e verilerini senkronize et"""
        logger.info("Ä°lÃ§e verilerini senkronize etme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        # Check if daily limit is reached
        if self.db.is_daily_limit_reached():
            logger.error("âš ï¸  GÃ¼nlÃ¼k servis limiti daha Ã¶nce aÅŸÄ±lmÄ±ÅŸ. BugÃ¼n iÃ§in iÅŸlem yapÄ±lamaz.")
            logger.info("Limit yarÄ±n sÄ±fÄ±rlanacak. Manuel olarak temizlemek iÃ§in: db.clear_daily_limit()")
            return
        client = TKGMClient(typename=settings.ILCELER, db_manager=self.db)
        content = client.fetch_features()
        
        if content is None:
            logger.error("TKGM servisinden ilÃ§e verisi alÄ±namadÄ±")
            return
        
        processor = WFSGeometryProcessor()
        
        try:
            all_features = processor.process_district_wfs_response(content)
            
            logger.info(f"Toplam {len(all_features)} geometri baÅŸarÄ±yla iÅŸlendi")
                
            if not all_features:
                logger.info("Ä°lÃ§e verisi bulunamadÄ±")
                return
            
            # VeritabanÄ±na kaydet
            try:
                self.db.insert_districts(all_features)
                logger.info(f"{len(all_features)} ilÃ§e veritabanÄ±na kaydedildi")
            except Exception as e:
                logger.error(f"VeritabanÄ±na kaydetme hatasÄ±: {e}")
            
        except Exception as e:
            logger.error(f"Ä°lÃ§e verilerini iÅŸlerken hata: {e}")


    def sync_neighbourhoods(self):
        """Mahalle verilerini senkronize et"""
        logger.info("Mahalle verilerini senkronize etme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        # Check if daily limit is reached
        if self.db.is_daily_limit_reached():
            logger.error("âš ï¸  GÃ¼nlÃ¼k servis limiti daha Ã¶nce aÅŸÄ±lmÄ±ÅŸ. BugÃ¼n iÃ§in iÅŸlem yapÄ±lamaz.")
            logger.info("Limit yarÄ±n sÄ±fÄ±rlanacak. Manuel olarak temizlemek iÃ§in: db.clear_daily_limit()")
            return

        client = TKGMClient(typename=settings.MAHALLELER, db_manager=self.db)
        content = client.fetch_features()
        
        if content is None:
            logger.error("TKGM servisinden mahalle verisi alÄ±namadÄ±")
            return
        
        processor = WFSGeometryProcessor()
        
        try:
            all_features = processor.process_neighbourhood_wfs_response(content)
            
            logger.info(f"Toplam {len(all_features)} geometri baÅŸarÄ±yla iÅŸlendi")
                
            if not all_features:
                logger.info("Mahalle verisi bulunamadÄ±")
                return
            
            # VeritabanÄ±na kaydet
            try:
                self.db.insert_neighbourhoods(all_features)
                logger.info(f"{len(all_features)} mahalle veritabanÄ±na kaydedildi")
            except Exception as e:
                logger.error(f"VeritabanÄ±na kaydetme hatasÄ±: {e}")
                
        except Exception as e:
            logger.error(f"Mahalle verilerini iÅŸlerken hata: {e}")
            return


    def sync_daily_parcels(self, start_date: Optional[datetime] = None, start_index: Optional[int] = 0):
        """GÃ¼nlÃ¼k parsel verilerini senkronize et - sayfalama ve tarih kontrolÃ¼ ile"""
        logger.info("GÃ¼nlÃ¼k parsel verilerini senkronize etme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        # Check if daily limit is reached
        if self.db.is_daily_limit_reached():
            logger.error("âš ï¸  GÃ¼nlÃ¼k servis limiti daha Ã¶nce aÅŸÄ±lmÄ±ÅŸ. BugÃ¼n iÃ§in iÅŸlem yapÄ±lamaz.")
            logger.info("Limit yarÄ±n sÄ±fÄ±rlanacak. Manuel olarak temizlemek iÃ§in: db.clear_daily_limit()")
            return
        
        max_features = settings.MAX_FEATURES
        current_index = start_index
        current_date = start_date if start_date else (datetime.now() - timedelta(days=1))
        end_date = datetime.now()
        
        # Ã–zet metrikleri
        summary_found = 0
        summary_saved = 0
        summary_pages = 0
        summary_empty_pages = 0
        summary_errors = 0
        features_count = 0
        
        # TKGMClient Ã¶rneÄŸini oluÅŸtur
        client = TKGMClient(
            typename=settings.PARSELLER,
            max_features=max_features,
            db_manager=self.db
        )
        
        while current_date < end_date and self.running:
            logger.info(f"[{current_date.isoformat()}] Index {current_index} - {current_index + max_features} arasÄ±nda iÅŸleniyor")
            summary_pages += 1
            
            # CQL filtre oluÅŸtur
            cql_filter = f"(onaydurum=1 and durum=3 and sistemguncellemetarihi>='{current_date.isoformat()}' and sistemguncellemetarihi<'{end_date.isoformat()}' and sistemkayittarihi<'{end_date.isoformat()}')"
            
            logger.info(f"Parsel verilerini Ã§ekmek iÃ§in kullanÄ±lan CQL filtre: {cql_filter}")
            content = client.fetch_features(start_index=current_index, cql_filter=cql_filter)
            
            if content is None:
                logger.error("TKGM servisinden parsel verisi alÄ±namadÄ±")
                summary_errors += 1
                break
            
            processor = WFSGeometryProcessor()
            if not self.running:
                break
            
            try:
                # XML'i parse et
                feature_members = processor.parse_wfs_xml(content)
                logger.info(f"Toplam {len(feature_members)} parsel bulundu")
                
                if len(feature_members) == 0:
                    logger.info(f"[{current_date.isoformat()}] Index {current_index} - {current_index + max_features} arasÄ±nda feature member bulunamadÄ±, bir sonraki sayfaya geÃ§iliyor")
                    summary_empty_pages += 1
                    current_date = current_date + timedelta(days=1)
                    current_index = 0
                    continue
                
                # Process each feature member
                all_features = processor.process_parcel_wfs_response(content)

                logger.info(f"Toplam {len(all_features)} geometri baÅŸarÄ±yla iÅŸlendi")
                
                if not all_features:
                    logger.info(f"[{current_date}] Index {current_index} - {current_index + max_features} arasÄ±nda parsel verisi bulunamadÄ±")
                    current_date = current_date + timedelta(days=1)
                    current_index = 0
                    continue
                
                features_count = len(all_features)
                logger.info(f"[{current_date}] Index {current_index} - {current_index + max_features} arasÄ±nda toplam {features_count} parsel Ã¶zelliÄŸi Ã§ekildi")
                summary_found += features_count
                
                # VeritabanÄ±na kaydet ve raporla
                if all_features:
                    try:
                        saved_count = self.db.insert_parcels(all_features)
                        unsaved_count = max(0, features_count - saved_count)
                        logger.info(
                            f"[{current_date}] Index {current_index} - {current_index + max_features} arasÄ±nda "
                            f"{saved_count} parsel veritabanÄ±na kaydedildi, {unsaved_count} kaydedilemedi"
                        )
                        summary_saved += saved_count

                        # BaÅŸarÄ±lÄ± Ã§ekim sonrasÄ± raporu Telegram'a gÃ¶nder
                        if self.notifier.is_configured():
                            try:
                                pull_msg = self.notifier.format_pull_report(
                                    date=current_date,
                                    start_index=current_index,
                                    end_index=current_index + max_features,
                                    found=features_count,
                                    saved=saved_count,
                                    unsaved=unsaved_count,
                                )
                                self.notifier.send_message(pull_msg)
                            except Exception as e:
                                logger.error(f"Servis Ã§ekim raporu gÃ¶nderilemedi: {e}")

                        # Sonraki sayfa iÃ§in start_index'i artÄ±r
                        current_index += max_features

                        # tk_settings tablosuna gÃ¼ncelleme yap - sadece tarih ve index
                        # AyarlarÄ± gÃ¼ncelle
                        self.db.update_setting(
                            query_date=current_date, 
                            start_index=current_index, 
                            scrape_type=SettingsRepository.TYPE_DAILY_SYNC
                        )
                        logger.info(
                            f"Parsel sorgu ayarlarÄ± gÃ¼ncellendi: query_date={current_date.strftime('%Y-%m-%d')}, start_index={current_index}"
                        )

                        # EÄŸer Ã§ekilen parsel sayÄ±sÄ± 1000'den azsa, tÃ¼m veriler Ã§ekilmiÅŸ demektir
                        if features_count < max_features:
                            logger.info(
                                f"[{current_date.isoformat()}] Index {current_index - max_features} - {current_index} arasÄ±nda toplam "
                                f"{features_count} parsel Ã§ekildi. TÃ¼m veriler Ã§ekildi."
                            )
                            current_date = current_date + timedelta(days=1)
                            current_index = 0

                    except Exception as e:
                        logger.error(f"VeritabanÄ±na kaydetme hatasÄ±: {e}")
                        summary_errors += 1
                        break
                else:
                    logger.info(f"[{current_date.isoformat()}] Index {current_index} - {current_index + max_features} arasÄ±nda kaydedilecek parsel verisi bulunamadÄ±")
                    current_date = current_date + timedelta(days=1)
                    current_index = 0
                    # Yeni tarihe geÃ§erken ayarlarÄ± gÃ¼ncelle
                    self.db.update_setting(query_date=current_date, start_index=current_index, scrape_type=SettingsRepository.TYPE_DAILY_SYNC)
                    continue
                
            except Exception as e:
                logger.error(f"Parsel verilerini iÅŸlerken hata: {e}")
                summary_errors += 1
                break
        
        # Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda final gÃ¼ncelleme
        self.db.update_setting(query_date=current_date, start_index=current_index, scrape_type=SettingsRepository.TYPE_DAILY_SYNC)
        
        if not self.running:
            logger.info("Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        else:
            logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda toplam {features_count} parsel Ã§ekildi. TÃ¼m veriler Ã§ekildi. Son iÅŸlenen tarih: {current_date.strftime('%Y-%m-%d')}")

    def sync_fully_parcels(self, start_index: Optional[int] = 0):
        """TÃ¼m parsel verilerini senkronize et - sayfalama ve tarih kontrolÃ¼ ile"""
        logger.info("TÃ¼m parsel verilerini senkronize etme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        # Check if daily limit is reached
        if self.db.is_daily_limit_reached():
            logger.error("âš ï¸  GÃ¼nlÃ¼k servis limiti daha Ã¶nce aÅŸÄ±lmÄ±ÅŸ. BugÃ¼n iÃ§in iÅŸlem yapÄ±lamaz.")
            logger.info("Limit yarÄ±n sÄ±fÄ±rlanacak. Manuel olarak temizlemek iÃ§in: db.clear_daily_limit()")
            return
        
        max_features = settings.MAX_FEATURES
        cutoff_date = settings.CUTOFF_DATE
        current_index = start_index
        current_date = datetime.now()
        features_count = 0
        
        # TKGMClient Ã¶rneÄŸini oluÅŸtur
        client = TKGMClient(
            typename=settings.PARSELLER,
            max_features=max_features,
            db_manager=self.db
        )
        
        while self.running:
            logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda iÅŸleniyor")
            
            cql_filter = f"(onaydurum=1 and sistemguncellemetarihi<'{cutoff_date}' and sistemkayittarihi<'{cutoff_date}')"
            
            logger.info(f"Parsel verilerini Ã§ekmek iÃ§in kullanÄ±lan CQL filtre: {cql_filter}")
            content = client.fetch_features(start_index=current_index, cql_filter=cql_filter)
            
            if content is None:
                logger.error("TKGM servisinden parsel verisi alÄ±namadÄ±")
                break
            
            processor = WFSGeometryProcessor()
            if not self.running:
                break
            
            try:
                # XML'i parse et
                feature_members = processor.parse_wfs_xml(content)
                logger.info(f"Toplam {len(feature_members)} parsel bulundu")
                
                if len(feature_members) == 0:
                    logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda feature member bulunamadÄ±, bir sonraki sayfaya geÃ§iliyor")
                    self.running = False
                    continue
                
                # Process each feature member
                all_features = processor.process_parcel_wfs_response(content)
                
                logger.info(f"Toplam {len(all_features)} geometri baÅŸarÄ±yla iÅŸlendi")
                    
                if not all_features:
                    logger.info("Bu sayfada parsel verisi bulunamadÄ±")
                    break
                
                features_count = len(all_features)
                logger.info(f"Toplam {features_count} parsel Ã¶zelliÄŸi Ã§ekildi")
                
                # VeritabanÄ±na kaydet
                if all_features:
                    try:
                        saved_count = self.db.insert_parcels(all_features)
                        unsaved_count = max(0, features_count - saved_count)
                        logger.info(f"{saved_count} parsel veritabanÄ±na kaydedildi, {unsaved_count} kaydedilemedi")
                        
                        # Sonraki sayfa iÃ§in start_index'i artÄ±r
                        current_index += max_features
                        
                        # tk_settings tablosuna gÃ¼ncelleme yap - sadece tarih ve index
                        self.db.update_setting(query_date=current_date, start_index=current_index, scrape_type=SettingsRepository.TYPE_FULLY_SYNC)
                        logger.info(f"Parsel sorgu ayarlarÄ± gÃ¼ncellendi: query_date={current_date.strftime('%Y-%m-%d')}, start_index={current_index}")

                        # EÄŸer Ã§ekilen parsel sayÄ±sÄ± 1000'den azsa, tÃ¼m veriler Ã§ekilmiÅŸ demektir
                        if features_count < max_features:
                            logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda toplam {features_count} parsel Ã§ekildi. TÃ¼m veriler Ã§ekildi.")
                            self.running = False
                    
                    except Exception as e:
                        logger.error(f"VeritabanÄ±na kaydetme hatasÄ±: {e}")
                        break
                else:
                    logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda kaydedilecek parsel verisi bulunamadÄ±")
                    self.running = False
                    # Yeni tarihe geÃ§erken ayarlarÄ± gÃ¼ncelle
                    self.db.update_setting(query_date=current_date, start_index=current_index, scrape_type=SettingsRepository.TYPE_FULLY_SYNC)
                    continue
                
            except Exception as e:
                logger.error(f"Parsel verilerini iÅŸlerken hata: {e}")
                break
        
        # Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda final gÃ¼ncelleme
        self.db.update_setting(query_date=current_date, start_index=current_index, scrape_type=SettingsRepository.TYPE_FULLY_SYNC)
        
        if not self.running:
            logger.info("Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        else:
            logger.info(f"Index {current_index} - {current_index + max_features} arasÄ±nda toplam {features_count} parsel Ã§ekildi. TÃ¼m veriler Ã§ekildi. Son iÅŸlenen tarih: {current_date.strftime('%Y-%m-%d')}")


    def show_stats(self):
        """VeritabanÄ± istatistiklerini gÃ¶rÃ¼ntÃ¼le"""
        try:
            stats = self.db.get_statistics()
            
            if not stats:
                logger.error("Ä°statistik verileri alÄ±namadÄ±")
                return
            
            print("\n" + "="*60)
            print("           TKGM VERÄ°TABANI Ä°STATÄ°STÄ°KLERÄ°")
            print("="*60)
            
            # Parsel Ä°statistikleri
            print("\nðŸ“Š PARSEL Ä°STATÄ°STÄ°KLERÄ°:")
            print(f"   â€¢ Toplam Parsel SayÄ±sÄ±      : {stats.get('total_parcels', 0):,}")
            print(f"   â€¢ BugÃ¼n Eklenen            : {stats.get('parcels_today', 0):,}")
            print(f"   â€¢ Son 7 GÃ¼nde Eklenen      : {stats.get('parcels_last_week', 0):,}")
            print(f"   â€¢ Toplam Alan (mÂ²)         : {stats.get('total_area', 0):,.2f}")
            
            # Tarih AralÄ±ÄŸÄ±
            date_range = stats.get('date_range', {})
            if date_range.get('min_date') and date_range.get('max_date'):
                print(f"   â€¢ Tarih AralÄ±ÄŸÄ±            : {date_range['min_date']} - {date_range['max_date']}")
            
            # DiÄŸer Veriler
            print("\nðŸ˜ï¸  DÄ°ÄžER VERÄ°LER:")
            print(f"   â€¢ Toplam Ä°lÃ§e SayÄ±sÄ±       : {stats.get('total_districts', 0):,}")
            print(f"   â€¢ Toplam Mahalle SayÄ±sÄ±    : {stats.get('total_neighbourhoods', 0):,}")
            
            # Sorgu Ä°statistikleri
            print("\nðŸ” SORGU Ä°STATÄ°STÄ°KLERÄ°:")
            print(f"   â€¢ Toplam Sorgu SayÄ±sÄ±      : {stats.get('total_queries', 0):,}")
            print(f"   â€¢ BugÃ¼n YapÄ±lan Sorgu      : {stats.get('queries_today', 0):,}")
            print(f"   â€¢ Ortalama SonuÃ§/Sorgu     : {stats.get('avg_features_per_query', 0):.1f}")
            
            # Sistem Bilgileri
            print("\nâš™ï¸  SÄ°STEM BÄ°LGÄ°LERÄ°:")
            if stats.get('last_update'):
                print(f"   â€¢ Son GÃ¼ncelleme           : {stats['last_update']}")
            
            # Mevcut Ayarlar
            current_settings = stats.get('current_settings', {})
            if current_settings:
                print("\nðŸ“‹ MEVCUT AYARLAR:")
                if current_settings.get('query_date'):
                    print(f"   â€¢ Sorgu Tarihi             : {current_settings['query_date']}")
                print(f"   â€¢ BaÅŸlangÄ±Ã§ Ä°ndeksi        : {current_settings.get('start_index', 0)}")
                if current_settings.get('last_updated'):
                    print(f"   â€¢ Ayar GÃ¼ncelleme          : {current_settings['last_updated']}")
            
            print("\n" + "="*60)
            
        except Exception as e:
            logger.error(f"Ä°statistikleri gÃ¶rÃ¼ntÃ¼lerken hata: {e}")

